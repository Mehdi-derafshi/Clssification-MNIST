{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrZrXaPvgNNtccZG4DzaRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehdi-derafshi/Neural-network/blob/main/Multi_class_image_classfication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e15208-a7ae-47d2-fcce-b9e2ab6680d4",
        "id": "Ap7TL3UpHL8t"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-28 06:57:49--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.207, 74.125.68.207, 64.233.170.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M  22.9MB/s    in 23s     \n",
            "\n",
            "2024-07-28 06:58:14 (21.1 MB/s) - ‘10_food_classes_all_data.zip’ saved [519183241/519183241]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "zip_ref =zipfile.ZipFile('10_food_classes_all_data.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "#zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk('10_food_classes_all_data'):\n",
        "  print(f\"There are {len(dirnames)} directions and {len(filenames)} images in '{dirpath}'.\")\n"
      ],
      "metadata": {
        "id": "Z83mvDArHPD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c84f6f-02a4-48ea-93dc-3538edc4a7ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directions and 0 images in '10_food_classes_all_data'.\n",
            "There are 10 directions and 0 images in '10_food_classes_all_data/test'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/sushi'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/steak'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/ice_cream'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/pizza'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/grilled_salmon'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/chicken_curry'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/chicken_wings'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/ramen'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/hamburger'.\n",
            "There are 0 directions and 250 images in '10_food_classes_all_data/test/fried_rice'.\n",
            "There are 10 directions and 0 images in '10_food_classes_all_data/train'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/sushi'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/steak'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/ice_cream'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/pizza'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/grilled_salmon'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/chicken_curry'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/chicken_wings'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/ramen'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/hamburger'.\n",
            "There are 0 directions and 750 images in '10_food_classes_all_data/train/fried_rice'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-QXuIXuMJE3b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# setup the train and test directories\n",
        "train_dir = \"10_food_classes_all_data/train/\"\n",
        "test_dir = \"10_food_classes_all_data/test/\""
      ],
      "metadata": {
        "id": "GgsAJunKMQPl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the class names\n",
        "\n",
        "import pathlib\n",
        "import numpy as np\n",
        "data_dir = pathlib.Path(train_dir)\n",
        "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoASwRMXBDXU",
        "outputId": "6141f1cb-2aa9-454e-f5cf-d7fb0a2969d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chicken_curry' 'chicken_wings' 'fried_rice' 'grilled_salmon' 'hamburger'\n",
            " 'ice_cream' 'pizza' 'ramen' 'steak' 'sushi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess the data"
      ],
      "metadata": {
        "id": "r44x1hWKFZqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale= 1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9eP54NHBSA3",
        "outputId": "a86fa8a0-f0e1-4263-badb-6dde01e5019a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iyShHMENJKw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a model"
      ],
      "metadata": {
        "id": "1dh0QLXPLmeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Activation\n",
        "import tensorflow as tf\n",
        "\n",
        "model_1 = Sequential([\n",
        "    Conv2D(10, 3, input_shape=(224, 224, 3)),\n",
        "    Activation(activation='relu'),\n",
        "\n",
        "  Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qxR-6C-tKQgr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model"
      ],
      "metadata": {
        "id": "WusymOL5IbyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_1.fit(train_data,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=len(train_data),\n",
        "                    validation_data=test_data,\n",
        "                    validation_steps=len(test_data))"
      ],
      "metadata": {
        "id": "-D6yUs9PPd8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "210254a8-2858-4962-8373-c8617d574ec4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "235/235 [==============================] - 35s 124ms/step - loss: 2.1168 - accuracy: 0.2323 - val_loss: 1.9920 - val_accuracy: 0.3100\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 27s 117ms/step - loss: 1.9128 - accuracy: 0.3316 - val_loss: 1.9386 - val_accuracy: 0.3176\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 28s 120ms/step - loss: 1.7247 - accuracy: 0.4087 - val_loss: 1.8359 - val_accuracy: 0.3512\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 27s 116ms/step - loss: 1.3011 - accuracy: 0.5645 - val_loss: 2.0279 - val_accuracy: 0.3344\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 29s 121ms/step - loss: 0.6712 - accuracy: 0.7821 - val_loss: 2.5922 - val_accuracy: 0.3112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model"
      ],
      "metadata": {
        "id": "hUZZg50cLNIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(test_data)"
      ],
      "metadata": {
        "id": "lva-z4wBMP1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb28c40-9959-45bc-aab9-b673cc8d9b50"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 6s 79ms/step - loss: 2.5922 - accuracy: 0.3112\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.5921788215637207, 0.31119999289512634]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust the model hyperparameters\n",
        "#### Let's try simplify our model"
      ],
      "metadata": {
        "id": "bZkmLOpSNIWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential([\n",
        "    Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OYz39fDMMmwA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(train_data,\n",
        "            epochs=5,\n",
        "            steps_per_epoch=len(train_data),\n",
        "            validation_data=test_data,\n",
        "            validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9ceT98-PKto",
        "outputId": "8b6509c2-5207-4fc5-9013-b97a9238b7ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "235/235 [==============================] - 29s 115ms/step - loss: 2.2060 - accuracy: 0.2276 - val_loss: 2.0148 - val_accuracy: 0.2792\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 26s 110ms/step - loss: 1.9239 - accuracy: 0.3283 - val_loss: 1.9187 - val_accuracy: 0.3296\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 27s 113ms/step - loss: 1.6189 - accuracy: 0.4616 - val_loss: 1.9599 - val_accuracy: 0.3144\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 26s 112ms/step - loss: 1.1595 - accuracy: 0.6175 - val_loss: 2.1283 - val_accuracy: 0.3368\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 26s 111ms/step - loss: 0.7192 - accuracy: 0.7835 - val_loss: 2.4126 - val_accuracy: 0.3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It didn't work, let's try data augmentation"
      ],
      "metadata": {
        "id": "R5YSIS91RK6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trying to reduce overfitting with data augmentation"
      ],
      "metadata": {
        "id": "_76IKftqRjgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=0.2,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf8Gw4UHQfoc",
        "outputId": "560522b6-7fe1-4cf5-9886-45b86b6d81aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = tf.keras.models.clone_model(model_1)\n",
        "\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_3.fit(train_data_augmented,\n",
        "            epochs=5,\n",
        "            steps_per_epoch=len(train_data_augmented),\n",
        "            validation_data=test_data,\n",
        "            validation_steps=len(test_data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0D5TGiMS3ey",
        "outputId": "29ca0136-e5dd-44aa-dce4-5bff19bf369e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "235/235 [==============================] - 101s 423ms/step - loss: 2.2453 - accuracy: 0.1593 - val_loss: 2.1817 - val_accuracy: 0.2132\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 100s 425ms/step - loss: 2.1144 - accuracy: 0.2437 - val_loss: 2.0082 - val_accuracy: 0.2808\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 100s 426ms/step - loss: 2.0642 - accuracy: 0.2679 - val_loss: 2.0333 - val_accuracy: 0.2936\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 100s 427ms/step - loss: 2.0371 - accuracy: 0.2844 - val_loss: 1.9524 - val_accuracy: 0.3248\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 99s 423ms/step - loss: 1.9602 - accuracy: 0.3152 - val_loss: 1.8137 - val_accuracy: 0.3940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f908c32f910>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWmNdzC3UT2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}