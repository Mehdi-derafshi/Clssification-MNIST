{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyILCDAWicc3Jc/hi4f1Pt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehdi-derafshi/Neural-network/blob/main/transfer_learning_in_tensorflow_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and becoming one with the data"
      ],
      "metadata": {
        "id": "1WFXEkoVxsCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "SO80vpQixe2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3f4439-8e81-4c66-82ae-35bfa3b11af0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-30 13:10:14--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.207, 173.194.203.207, 74.125.199.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   158MB/s    in 1.0s    \n",
            "\n",
            "2024-07-30 13:10:15 (158 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk('10_food_classes_10_percent'):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "xcVCyQghyXdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5d40d1-1d51-4294-e1c4-8b2636d5930a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create data loaders (preparing the data)\n",
        "\n",
        "We'll use the 'ImageDataGenerator' class to load in our images in batches."
      ],
      "metadata": {
        "id": "grJyQMbS3-22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print('Training images:')\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode='categorical')\n",
        "\n",
        "print(\"testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode = \"categorical\")"
      ],
      "metadata": {
        "id": "qBHgZFMF3V99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10bfa157-6bad-471d-a96c-037715b352ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks"
      ],
      "metadata": {
        "id": "fPz_4FRK8_EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "X2ysjIyl89lH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating models using TensorFlow Hub"
      ],
      "metadata": {
        "id": "hNtr_V2wkUI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "c2d-3SWTrApn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "JGp2OzTzyVzQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False,\n",
        "                                           name='feature_extraction_layer',\n",
        "                                           input_shape=IMAGE_SHAPE+(3,))\n",
        "\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    layers.Dense(num_classes, activation='softmax', name='output_layer')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "UiybQwKxqxXI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "\n",
        "resnet_model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Q8wDQCkQqxTj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                         experiment_name=\"resnet50V2\")])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCiqmY0lqxQV",
        "outputId": "cac9baa4-c425-4067-bff7-ad2b5c0f077b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20240730-131602\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 22s 623ms/step - loss: 1.8377 - accuracy: 0.3907 - val_loss: 1.1453 - val_accuracy: 0.6584\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 10s 441ms/step - loss: 0.8681 - accuracy: 0.7547 - val_loss: 0.8469 - val_accuracy: 0.7204\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 10s 447ms/step - loss: 0.6023 - accuracy: 0.8307 - val_loss: 0.7510 - val_accuracy: 0.7552\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 13s 538ms/step - loss: 0.4575 - accuracy: 0.8813 - val_loss: 0.6946 - val_accuracy: 0.7708\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 13s 540ms/step - loss: 0.3804 - accuracy: 0.9147 - val_loss: 0.6663 - val_accuracy: 0.7784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "efficientnet_model = create_model(model_url=efficientnet_url, # use EfficientNetB0 TensorFlow Hub URL\n",
        "                                  num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "\n",
        "efficientnet_model.compile(loss='categorical_crossentropy',\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "\n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
        "                                              epochs=5,\n",
        "                                              steps_per_epoch=len(train_data_10_percent),\n",
        "                                              validation_data=test_data,\n",
        "                                              validation_steps=len(test_data),\n",
        "                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "\n",
        "                                                                                     experiment_name=\"efficientnetB0\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgBhDus1qxMr",
        "outputId": "f1cdd8a2-4399-40b5-ed19-d045bef4ab90"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/efficientnetB0/20240730-131845\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 23s 523ms/step - loss: 1.8240 - accuracy: 0.4267 - val_loss: 1.2673 - val_accuracy: 0.7272\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 12s 533ms/step - loss: 1.0540 - accuracy: 0.7707 - val_loss: 0.8583 - val_accuracy: 0.8196\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 10s 410ms/step - loss: 0.7512 - accuracy: 0.8267 - val_loss: 0.6967 - val_accuracy: 0.8400\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 10s 425ms/step - loss: 0.6051 - accuracy: 0.8600 - val_loss: 0.6098 - val_accuracy: 0.8564\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 9s 384ms/step - loss: 0.5124 - accuracy: 0.8813 - val_loss: 0.5571 - val_accuracy: 0.8584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The EfficientNetB0 model does even better than the ResNetV250 model! Achieving over 85% accuracy on the test set...again with only 10% of the training data."
      ],
      "metadata": {
        "id": "RrjCebibyi8g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JaAkwPOzwsCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8aHEmaAwr6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kZsqZ__wrqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ngupWUiwrhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3MnwBg8wrZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HvO3IS9ewrSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Khf17SuuwrJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-QLLyjnwrAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fxics2TLwq5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QoWBV1-4wqxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AVo4BtdIwqpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szFL99xqwqe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}